{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# AIT Development notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## notebook of structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "| #  | Name                                               | cells | for_dev | edit               | description                                                                |\n",
    "|----|----------------------------------------------------|-------|---------|--------------------|----------------------------------------------------------------------------|\n",
    "| 1  | [Environment detection](##1-Environment-detection) | 1     | No      | uneditable         | detect whether the notebook are invoked for packaging or in production     |\n",
    "| 2  | [Preparing AIT SDK](##2-Preparing-AIT-SDK)         | 1     | Yes     | uneditable         | download and install AIT SDK                                               |\n",
    "| 3  | [Dependency Management](##3-Dependency-Management) | 3     | Yes     | required(cell #2)  | generate requirements.txt for Docker container                             |\n",
    "| 4  | [Importing Libraries](##4-Importing-Libraries)     | 2     | Yes     | required(cell #1)  | import required libraries                                                  |\n",
    "| 5  | [Manifest Generation](##5-Manifest-Generation)     | 1     | Yes     | required           | generate AIT Manifest                                                      |\n",
    "| 6  | [Prepare for the Input](##6-Prepare-for-the-Input) | 1     | Yes     | required           | generate AIT Input JSON (inventory mapper)                                 |\n",
    "| 7  | [Initialization](##7-Initialization)               | 1     | No      | uneditable         | initialization for AIT execution                                           |\n",
    "| 8  | [Function definitions](##8-Function-definitions)   | N     | No      | required           | define functions invoked from Main area.<br> also define output functions. |\n",
    "| 9  | [Main Algorithms](##9-Main-Algorithms)             | 1     | No      | required           | area for main algorithms of an AIT                                         |\n",
    "| 10 | [Entry point](##10-Entry-point)                    | 1     | No      | uneditable         | an entry point where Qunomon invoke this AIT from here                     |\n",
    "| 11 | [License](##11-License)                            | 1     | Yes     | required           | generate license information                                               |\n",
    "| 12 | [Deployment](##12-Deployment)                      | 1     | Yes     | uneditable         | convert this notebook to the python file for packaging purpose             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## notebook template revision history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "1.0.1 2020/10/21\n",
    "\n",
    "* add revision history\n",
    "* separate `create requirements and pip install` editable and noeditable\n",
    "* separate `import` editable and noeditable\n",
    "\n",
    "1.0.0 2020/10/12\n",
    "\n",
    "* new cerarion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #1 Environment detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Determine whether to start AIT or jupyter by startup argument\n",
    "import sys\n",
    "is_ait_launch = (len(sys.argv) == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #2 Preparing AIT SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "if not is_ait_launch:\n",
    "    # get ait-sdk file name\n",
    "    from pathlib import Path\n",
    "    from glob import glob\n",
    "    import re\n",
    "    import os\n",
    "\n",
    "    current_dir = %pwd\n",
    "\n",
    "    ait_sdk_path = \"./ait_sdk-*-py3-none-any.whl\"\n",
    "    ait_sdk_list = glob(ait_sdk_path)\n",
    "    ait_sdk_name = os.path.basename(ait_sdk_list[-1])\n",
    "\n",
    "    # install ait-sdk\n",
    "    !pip install -q --upgrade pip\n",
    "    !pip install -q --no-deps --force-reinstall ./$ait_sdk_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #3 Dependency Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #3-1 [uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_requirements_generator import AITRequirementsGenerator\n",
    "    requirements_generator = AITRequirementsGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #3-2 [required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    requirements_generator.add_package('mlflow', '2.18.0')\n",
    "    requirements_generator.add_package('pandas', '2.2.3')\n",
    "    requirements_generator.add_package('evaluate', '0.4.3')\n",
    "    requirements_generator.add_package('ipywidgets', '8.1.5')\n",
    "    requirements_generator.add_package('transformers', '4.47.0')\n",
    "    requirements_generator.add_package('torch', '2.5.1')\n",
    "    requirements_generator.add_package('torchvision', '0.20.1')\n",
    "    requirements_generator.add_package('torchaudio', '2.5.1')\n",
    "    requirements_generator.add_package('rouge-score', '0.1.2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #3-3 [uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "if not is_ait_launch:\n",
    "    requirements_generator.add_package(f'./{ait_sdk_name}')\n",
    "    requirements_path = requirements_generator.create_requirements(current_dir)\n",
    "\n",
    "    !pip install -q -r $requirements_path "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #4 Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #4-1 [required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import if you need modules cell\n",
    "\n",
    "import mlflow\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "from rouge_score import rouge_scorer\n",
    "from collections import Counter\n",
    "from mlflow.metrics import MetricValue\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### #4-2 [uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# must use modules\n",
    "from os import path\n",
    "import shutil  # do not remove\n",
    "from ait_sdk.common.files.ait_input import AITInput  # do not remove\n",
    "from ait_sdk.common.files.ait_output import AITOutput  # do not remove\n",
    "from ait_sdk.common.files.ait_manifest import AITManifest  # do not remove\n",
    "from ait_sdk.develop.ait_path_helper import AITPathHelper  # do not remove\n",
    "from ait_sdk.utils.logging import get_logger, log, get_log_path  # do not remove\n",
    "from ait_sdk.develop.annotation import measures, resources, downloads, ait_main  # do not remove\n",
    "# must use modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #5 Manifest Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_manifest_generator import AITManifestGenerator\n",
    "    manifest_genenerator = AITManifestGenerator(current_dir)\n",
    "    manifest_genenerator.set_ait_name('eval_llm_rouge_score')\n",
    "    manifest_genenerator.set_ait_description('MLFlowを使用して、LLMモデルでテキストに対してレジュメ生成し、その生成されたテキストの品質を評価します。LLM評価基準を用いて、テキストのROUGEスコアを計算し、テキストの質を数値化します。')\n",
    "    manifest_genenerator.set_ait_source_repository('https://github.com/aistairc/Qunomon_AIT_eval_llm_rouge_score')\n",
    "    manifest_genenerator.set_ait_version('1.0')\n",
    "    manifest_genenerator.add_ait_licenses('Apache License Version 2.0')\n",
    "    manifest_genenerator.add_ait_keywords('LLM')\n",
    "    manifest_genenerator.add_ait_keywords('MLFlow')\n",
    "    manifest_genenerator.add_ait_keywords('ROUGE')\n",
    "    manifest_genenerator.set_ait_quality('https://ait-hub.pj.aist.go.jp/ait-hub/api/0.0.1/qualityDimensions/機械学習品質マネジメントガイドライン第三版/C-1機械学習モデルの正確性')\n",
    "    inventory_requirement_data = manifest_genenerator.format_ait_inventory_requirement(format_=['json'])\n",
    "    manifest_genenerator.add_ait_inventories(name='generate_data', \n",
    "                                              type_='dataset', \n",
    "                                              description='説明とレジュメのデータセット \\nJSON形式{inputs:array, references:array}\\n例：{inputs: [Artificial intelligence is rapidly transforming industries.], references: [AI is revolutionizing industries by enhancing data processing and decision-making.]', \n",
    "                                              requirement=inventory_requirement_data)\n",
    "    inventory_requirement_model = manifest_genenerator.format_ait_inventory_requirement(format_=['ALL'])\n",
    "    manifest_genenerator.add_ait_inventories(name='llm_model_dir', \n",
    "                                              type_='model', \n",
    "                                              description='事前にトレーニング済みの大規模言語モデルと、そのモデルの設定ファイルを保存したディレクトリ\\n 例:T5, GPT-3\\n モデルファイルは、config.json, model.safetensors, generation_config.json, special_tokens_map.json, tokenizer_config.json, tokenizer.jsonを含む', \n",
    "                                              requirement=inventory_requirement_model)\n",
    "    manifest_genenerator.add_ait_measures(name='ROUGE1_Score', \n",
    "                                           type_='float', \n",
    "                                           description='計算されたROUGE1スコア', \n",
    "                                           structure='single',\n",
    "                                           min='0')\n",
    "    manifest_genenerator.add_ait_measures(name='ROUGE2_Score', \n",
    "                                           type_='float', \n",
    "                                           description='計算されたROUGE2スコア', \n",
    "                                           structure='single',\n",
    "                                           min='0')\n",
    "    manifest_genenerator.add_ait_measures(name='ROUGE_L_Score', \n",
    "                                           type_='float', \n",
    "                                           description='計算されたROUGE_Lスコア', \n",
    "                                           structure='single',\n",
    "                                           min='0')\n",
    "    manifest_genenerator.add_ait_measures(name='ROUGE_W_Score', \n",
    "                                           type_='float', \n",
    "                                           description='計算されたROUGE_Wスコア', \n",
    "                                           structure='single',\n",
    "                                           min='0')\n",
    "    manifest_genenerator.add_ait_measures(name='ROUGE_S_Score', \n",
    "                                           type_='float', \n",
    "                                           description='計算されたROUGE_Sスコア', \n",
    "                                           structure='single',\n",
    "                                           min='0')\n",
    "    manifest_genenerator.add_ait_resources(name='rouge_score_table',  \n",
    "                                           type_='table', \n",
    "                                           description='ROUGEスコアが最も低い10セットのデータサンプル')\n",
    "    manifest_genenerator.add_ait_downloads(name='Log', \n",
    "                                            description='AIT実行ログ')\n",
    "    manifest_genenerator.add_ait_downloads(name='MLFlow_table', \n",
    "                                            description='MLFlow実行結果CSV')\n",
    "    manifest_path = manifest_genenerator.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #6 Prepare for the Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    from ait_sdk.common.files.ait_input_generator import AITInputGenerator\n",
    "    input_generator = AITInputGenerator(manifest_path)\n",
    "    input_generator.add_ait_inventories(name='generate_data',\n",
    "                                     value='generate_data.json')\n",
    "    input_generator.add_ait_inventories(name='llm_model_dir',\n",
    "                                     value='model')\n",
    "    input_generator.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #7 Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "logger = get_logger()\n",
    "\n",
    "ait_manifest = AITManifest()\n",
    "ait_input = AITInput(ait_manifest)\n",
    "ait_output = AITOutput(ait_manifest)\n",
    "\n",
    "if is_ait_launch:\n",
    "    # launch from AIT\n",
    "    current_dir = path.dirname(path.abspath(__file__))\n",
    "    path_helper = AITPathHelper(argv=sys.argv, ait_input=ait_input, ait_manifest=ait_manifest, entry_point_dir=current_dir)\n",
    "else:\n",
    "    # launch from jupyter notebook\n",
    "    # ait.input.json make in input_dir\n",
    "    input_dir = '/usr/local/qai/mnt/ip/job_args/1/1'\n",
    "    current_dir = %pwd\n",
    "    path_helper = AITPathHelper(argv=['', input_dir], ait_input=ait_input, ait_manifest=ait_manifest, entry_point_dir=current_dir)\n",
    "\n",
    "ait_input.read_json(path_helper.get_input_file_path())\n",
    "ait_manifest.read_json(path_helper.get_manifest_file_path())\n",
    "\n",
    "### do not edit cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #8 Function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@measures(ait_output, 'ROUGE1_Score')\n",
    "def mean_rouge1(mean_rouge):\n",
    "    return mean_rouge\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'ROUGE2_Score')\n",
    "def mean_rouge2(mean_rouge):\n",
    "    return mean_rouge\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'ROUGE_L_Score')\n",
    "def mean_rougeL(mean_rouge):\n",
    "    return mean_rouge\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'ROUGE_W_Score')\n",
    "def mean_rougeW(mean_rouge):\n",
    "    return mean_rouge\n",
    "\n",
    "@log(logger)\n",
    "@measures(ait_output, 'ROUGE_S_Score')\n",
    "def mean_rougeS(mean_rouge):\n",
    "    return mean_rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@resources(ait_output, path_helper, 'rouge_score_table', 'rouge_score_table.csv')\n",
    "def rouge_score_table(df, file_path: str=None) -> None:\n",
    "    df.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "# ROUGE_Wを計算する\n",
    "def _compute_rouge_w(reference, candidate, beta=1.2):\n",
    "    def lcs(x, y):\n",
    "        n, m = len(x), len(y)\n",
    "        dp = [[0] * (m + 1) for _ in range(n + 1)]\n",
    "        for i in range(1, n + 1):\n",
    "            for j in range(1, m + 1):\n",
    "                if x[i - 1] == y[j - 1]:\n",
    "                    dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "                else:\n",
    "                    dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "        return dp[n][m]\n",
    "\n",
    "    ref_tokens = reference.split()\n",
    "    cand_tokens = candidate.split()\n",
    "    lcs_length = lcs(ref_tokens, cand_tokens)\n",
    "    precision = lcs_length / len(cand_tokens) if cand_tokens else 0\n",
    "    recall = lcs_length / len(ref_tokens) if ref_tokens else 0\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    return (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall)\n",
    "\n",
    "# ROUGE_Sを計算する\n",
    "def _compute_rouge_s(reference, candidate):\n",
    "    def skip_bigrams(text):\n",
    "        tokens = text.split()\n",
    "        return Counter((tokens[i], tokens[j]) for i in range(len(tokens)) for j in range(i + 1, len(tokens)))\n",
    "\n",
    "    ref_bigrams = skip_bigrams(reference)\n",
    "    cand_bigrams = skip_bigrams(candidate)\n",
    "    overlap = sum((ref_bigrams & cand_bigrams).values())\n",
    "    precision = overlap / sum(cand_bigrams.values()) if cand_bigrams else 0\n",
    "    recall = overlap / sum(ref_bigrams.values()) if ref_bigrams else 0\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "def standard_aggregations(scores):\n",
    "    return {\"mean\": np.mean(scores)}\n",
    "\n",
    "# ROUGE_Wの評価メトリクス\n",
    "def rouge_w_fn(predictions, targets):\n",
    "    scores = []\n",
    "    for pred, target in zip(predictions, targets):\n",
    "        score = _compute_rouge_w(target, pred)\n",
    "        scores.append(score)\n",
    "    # 集約\n",
    "    return MetricValue(scores=scores, aggregate_results=standard_aggregations(scores))\n",
    "# ROUGE_Sの評価メトリクス\n",
    "def rouge_s_fn(predictions, targets):\n",
    "    scores = []\n",
    "    for pred, target in zip(predictions, targets):\n",
    "        score = _compute_rouge_s(target, pred)\n",
    "        scores.append(score)\n",
    "    # 集約\n",
    "    return MetricValue(scores=scores, aggregate_results=standard_aggregations(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@downloads(ait_output, path_helper, 'MLFlow_table', 'MLFlow_table.csv')\n",
    "def eval_result(eval_table, file_path: str=None) -> str:\n",
    "    eval_table.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@downloads(ait_output, path_helper, 'Log', 'ait.log')\n",
    "def move_log(file_path: str=None) -> str:\n",
    "    shutil.move(get_log_path(), file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #9 Main Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log(logger)\n",
    "@ait_main(ait_output, path_helper, is_ait_launch)\n",
    "def main() -> None:\n",
    "    # 並列処理の警告を抑制\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "    with open(ait_input.get_inventory_path('generate_data'), \"r\") as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    eval_data = pd.DataFrame(json_data)\n",
    "    \n",
    "    # ローカルに保存されたLLMモデルを読み込む\n",
    "    tokenizer_path = ait_input.get_inventory_path('llm_model_dir')\n",
    "    model_path = ait_input.get_inventory_path('llm_model_dir')\n",
    "    \n",
    "    # Transformers を使用してモデルとトークナイザをロード\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "\n",
    "    # パイプラインの作成\n",
    "    device = 0 if torch.cuda.is_available() else -1  # GPUが利用可能なら0、そうでなければ-1（CPU）\n",
    "    text2text_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "    # モデルの予測関数\n",
    "    def predict(inputs):\n",
    "        outputs = text2text_pipeline(inputs, max_new_tokens=50)\n",
    "        return outputs[0][\"generated_text\"]\n",
    "\n",
    "    # 予測値を計算してデータに追加\n",
    "    eval_data[\"predictions\"] = eval_data[\"inputs\"].apply(predict)\n",
    "        \n",
    "    with mlflow.start_run() as run:\n",
    "        mlflow.transformers.log_model(\n",
    "            transformers_model=text2text_pipeline,  # パイプラインを渡す\n",
    "            artifact_path=\"model\",\n",
    "        )\n",
    "        # ログされたモデルの URI を取得\n",
    "        logged_model_uri = f\"runs:/{run.info.run_id}/model\"\n",
    "        # ROUGE_WとROUGE_Sの評価メソッド\n",
    "        rouge_w_metric = mlflow.metrics.make_metric(\n",
    "            eval_fn=rouge_w_fn, greater_is_better=True, name=\"rougeW\"\n",
    "        )\n",
    "\n",
    "        rouge_s_metric = mlflow.metrics.make_metric(\n",
    "            eval_fn=rouge_s_fn, greater_is_better=True, name=\"rougeS\"\n",
    "        )\n",
    "        results = mlflow.evaluate(\n",
    "            model=logged_model_uri,\n",
    "            data=eval_data,\n",
    "            targets=\"references\",\n",
    "            predictions=\"predictions\",\n",
    "            model_type=None,\n",
    "            extra_metrics=[\n",
    "                mlflow.metrics.rouge1(),\n",
    "                mlflow.metrics.rouge2(),\n",
    "                mlflow.metrics.rougeL(),\n",
    "                rouge_w_metric,\n",
    "                rouge_s_metric\n",
    "            ]\n",
    "        )\n",
    "        # 評価結果表示\n",
    "        print(f\"See evaluation table below: \\n{results.metrics}\")\n",
    "        # 評価結果テーブル\n",
    "        eval_table = results.tables[\"eval_results_table\"]\n",
    "        eval_result(eval_table)\n",
    "        # 評価結果テーブル表示\n",
    "        print(f\"See evaluation table below: \\n{eval_table}\")\n",
    "        # ROUGEの平均スコアをmeasuresに設定\n",
    "        mean_rouge1(results.metrics.get(\"rouge1/v1/mean\", 0))\n",
    "        mean_rouge2(results.metrics.get(\"rouge2/v1/mean\", 0))\n",
    "        mean_rougeL(results.metrics.get(\"rougeL/v1/mean\", 0))\n",
    "        mean_rougeW(results.metrics.get(\"rougeW/mean\", 0))\n",
    "        mean_rougeS(results.metrics.get(\"rougeS/mean\", 0))\n",
    "        # ROUGEスコアで昇順にソートし、上位10行を取得\n",
    "        sorted_df = eval_table.sort_values(by=\"rouge1/v1/score\", ascending=True).head(10)\n",
    "        rouge_score_table(sorted_df)\n",
    "            \n",
    "    # AIT実行ログ出力\n",
    "    move_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #10 Entry point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "2024/12/18 13:39:18 WARNING mlflow.transformers: The model card could not be retrieved from the hub due to [Errno 21] Is a directory: '/usr/local/qai/inventory/model'\n",
      "2024/12/18 13:39:18 WARNING mlflow.transformers: Unable to find license information for this model. Please verify permissible usage for the model you are storing prior to use.\n",
      "2024/12/18 13:39:55 WARNING mlflow.transformers.model_io: Could not specify device parameter for this pipeline type.Falling back to loading the model with the default device.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbacc96a1b24e06b5928adc0f6fed0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "2024/12/18 13:40:05 INFO mlflow.models.evaluation.evaluators.default: Computing model predictions.\n",
      "2024/12/18 13:41:18 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eefc311962f541ebbc68dcc0028772eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See evaluation table below: \n",
      "{'rouge1/v1/mean': 0.1874345943911161, 'rouge1/v1/variance': 0.005983454658825159, 'rouge1/v1/p90': 0.28181818181818175, 'rouge2/v1/mean': 0.04, 'rouge2/v1/variance': 0.0024000000000000002, 'rouge2/v1/p90': 0.1, 'rougeL/v1/mean': 0.1874345943911161, 'rougeL/v1/variance': 0.005983454658825159, 'rougeL/v1/p90': 0.28181818181818175, 'rougeW/mean': 0.12809265749231588, 'rougeS/mean': 0.01350375939849624}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579cd1e8fe8e466e838319d77696a74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See evaluation table below: \n",
      "                                              inputs  \\\n",
      "0  Artificial intelligence is rapidly transformin...   \n",
      "1  Global warming is causing severe weather chang...   \n",
      "2  The development of renewable energy sources li...   \n",
      "3  Space exploration has advanced significantly, ...   \n",
      "4  Education systems worldwide are embracing digi...   \n",
      "5  Cybersecurity threats are increasing with the ...   \n",
      "6  Advances in biotechnology, such as CRISPR, hav...   \n",
      "7  Social media platforms are under scrutiny for ...   \n",
      "8  Electric vehicles (EVs) are gaining popularity...   \n",
      "9  Water scarcity is a pressing global issue, dri...   \n",
      "\n",
      "                                         predictions  \\\n",
      "0  from healthcare to finance.. is rapidly transf...   \n",
      "1  is causing severe weather changes worldwide.. ...   \n",
      "2  ... They are also more affordable than fossil ...   \n",
      "3  has advanced significantly... Humans have a lo...   \n",
      "4  .. are embracing digital transformation. are e...   \n",
      "5  .. are accelerating the growth of digital infr...   \n",
      "6                   , such as CRISPR... CRISPR. CRIS   \n",
      "7  . social media platforms are under scrutiny fo...   \n",
      "8  are gaining popularity as an eco-friendly alte...   \n",
      "9                        ..... is a global issue. is   \n",
      "\n",
      "                                          references  rouge1/v1/score  \\\n",
      "0  AI is revolutionizing industries by enhancing ...         0.173913   \n",
      "1  Global warming intensifies weather changes, th...         0.181818   \n",
      "2  Renewable energy is key to reducing fossil fue...         0.090909   \n",
      "3  Space exploration seeks to expand knowledge an...         0.181818   \n",
      "4  Digital tools are transforming global educatio...         0.222222   \n",
      "5  Rising cybersecurity threats demand stronger p...         0.111111   \n",
      "6  Biotechnology advances like CRISPR offer trans...         0.133333   \n",
      "7  Addressing misinformation on social media dema...         0.272727   \n",
      "8  EVs are promoted as a green alternative to cut...         0.363636   \n",
      "9  Sustainable practices are crucial to combat gl...         0.142857   \n",
      "\n",
      "   rouge2/v1/score  rougeL/v1/score  rougeW/score  rougeS/score  \n",
      "0              0.0         0.173913      0.092424      0.000000  \n",
      "1              0.1         0.181818      0.092424      0.000000  \n",
      "2              0.0         0.090909      0.086280      0.000000  \n",
      "3              0.1         0.181818      0.096063      0.000000  \n",
      "4              0.0         0.222222      0.106272      0.000000  \n",
      "5              0.0         0.111111      0.110507      0.000000  \n",
      "6              0.0         0.133333      0.000000      0.000000  \n",
      "7              0.1         0.272727      0.184012      0.015038  \n",
      "8              0.1         0.363636      0.384252      0.120000  \n",
      "9              0.0         0.142857      0.128692      0.000000  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #11 License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[required]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ait_owner='AIST'\n",
    "ait_creation_year='2024'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### #12 Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[uneditable] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "if not is_ait_launch:\n",
    "    from ait_sdk.deploy import prepare_deploy\n",
    "    from ait_sdk.license.license_generator import LicenseGenerator\n",
    "    \n",
    "    current_dir = %pwd\n",
    "    prepare_deploy(ait_sdk_name, current_dir, requirements_path)\n",
    "    \n",
    "    # output License.txt\n",
    "    license_generator = LicenseGenerator()\n",
    "    license_generator.write('../top_dir/LICENSE.txt', ait_creation_year, ait_owner)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc00c6a56d87bd8bd7773e730c60ddfdb8804da6b7537df09499efbcf81630f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
